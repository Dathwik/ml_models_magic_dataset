# MAGIC Gamma Telescope Classification

Machine Learning pipeline for binary classification of high-energy particle events using the MAGIC Gamma Telescope dataset from the UCI Machine Learning Repository.

---

## ğŸ“Š Dataset

**Source:**  
Dua, D. and Graff, C. (2019). UCI Machine Learning Repository  
MAGIC Gamma Telescope Dataset  
http://archive.ics.uci.edu/ml

**Dataset Details:**
- 10 continuous numerical features
- Binary classification:
  - `1` â†’ Gamma
  - `0` â†’ Hadron
- 19,020 total samples

---

## ğŸ¯ Problem Statement

Build and evaluate machine learning models to classify whether a detected particle event corresponds to a **gamma signal** or a **hadron background event**.

---

## ğŸ” Data Processing Pipeline

- Dataset shuffled before splitting
- Train / Validation / Test split:
  - 60% Train
  - 20% Validation
  - 20% Test
- Feature scaling using `StandardScaler`
- Class imbalance handled using `RandomOverSampler` (applied only to training set)

---

## ğŸ¤– Models Implemented

### 1ï¸âƒ£ K-Nearest Neighbors (KNN)
- n_neighbors = 5  
- Test Accuracy: **82%**

### 2ï¸âƒ£ Gaussian Naive Bayes
- Test Accuracy: **72%**

### 3ï¸âƒ£ Logistic Regression
- Test Accuracy: **77%**

### 4ï¸âƒ£ Support Vector Machine (SVM)
- Test Accuracy: **87%**

### 5ï¸âƒ£ Neural Network (TensorFlow / Keras)

Architecture:
- Dense (ReLU)
- Dropout
- Dense (ReLU)
- Dropout
- Output (Sigmoid)

Hyperparameters tuned:
- Hidden units: 16, 32, 64
- Dropout: 0, 0.2
- Learning rate: 0.01, 0.005, 0.001
- Batch size: 32, 64, 128
- Epochs: 100

Best Neural Network Performance:
- Accuracy: **87%**
- Precision (Gamma): 0.89
- Recall (Gamma): 0.93
- F1-score (Gamma): 0.91

---

## ğŸ“ˆ Model Comparison

| Model | Test Accuracy |
|--------|--------------|
| Naive Bayes | 72% |
| Logistic Regression | 77% |
| KNN | 82% |
| SVM | 87% |
| Neural Network | 87% |

SVM and Neural Network achieved the best overall performance.

---

## ğŸ›  Tech Stack

- Python
- NumPy
- Pandas
- Matplotlib
- scikit-learn
- imbalanced-learn
- TensorFlow / Keras

---

## ğŸš€ How to Run

Clone the repository:

```bash
git clone https://github.com/Dathwik/ml_models_magic_dataset.git
cd ml_models_magic_dataset
```

Install dependencies:

```bash
pip install -r requirements.txt
```

Launch notebook:

```bash
jupyter notebook
```

---

## ğŸ“‚ Repository Structure

```
ml_models_magic_dataset/
â”‚
â”œâ”€â”€ magic04.data
â”œâ”€â”€ fcc_MAGIC.ipynb.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ’¡ Key Takeaways

- Feature scaling significantly improves performance of distance-based models.
- Handling class imbalance improves recall on minority class.
- SVM performs strongly on structured tabular data.
- Proper hyperparameter tuning allows neural networks to match classical ML models.
